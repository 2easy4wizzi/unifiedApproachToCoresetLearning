C:\Users\GiladEiniKbyLake\.conda\envs\AutoCL2\python.exe D:/workspace/2019SGD/DataReduction/SVM/mainSVM.py
--------------------------------------------------------------------------------
main_wrapper:
* Run started at 16-06-2022 15:46:51
* Python Version 3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]
* Operating System uname_result(system='Windows', node='Wizzi-Dorms', release='10', version='10.0.19041', machine='AMD64', processor='Intel64 Family 6 Model 158 Stepping 9, GenuineIntel')
* Interpreter: C:\Users\GiladEiniKbyLake\.conda\envs\AutoCL2\python.exe
* wizzi_utils Version 7.0.15
* Working Dir: D:\workspace\2019SGD\DataReduction\SVM
* Computer Mac: 70:4D:7B:8A:65:EE
* CPU Info: AMD64, Intel64 Family 6 Model 158 Stepping 9, GenuineIntel, Physical cores 4, Total cores 8, Frequency 3601.00Mhz, CPU Usage 68.8%
* Physical Memory: C: Total 232.33 GB, Used 208.24 GB(89.60%), Free 24.09 GB, D: Total 931.39 GB, Used 241.0 GB(25.90%), Free 690.39 GB, E: PermissionError: [WinError 21] The device is not ready: 'E', G: Total 17.0 GB, Used 3.2 GB(18.80%), Free 13.8 GB
* RAM: Total 15.94 GB, Used 6.68 GB(41.9%), Available 9.26 GB
* CUDA Version: v10.2 (cuDNN Version 7.6.5) (Turned off)
* PyTorch Version 1.8.1+cu101 - GPU detected ? False
Function <function main at 0x000001B09E900C80> started:
--------------------------------------------------------------------------------
working on CPU
A_train(numpy.ndarray,s=(16107, 9),dtype=float64): [[0.03, 0.23, -0.24, -0.3, -0.38, -0.74, 1.14, 1.2, -1.0], [-1.26, -1.4, 0.25, 0.23, -0.17, 0.42, -0 ...too long
A_test(numpy.ndarray,s=(1790, 9),dtype=float64): [[0.29, 0.24, -0.37, -0.29, -0.35, -0.66, 0.3, 0.23, -1.0], [1.24, -0.29, -0.66, -0.24, -0.25, 0.07, ...too long
SP_train(numpy.ndarray,s=(16107,),dtype=float64): [0.04, 0.06, 0.04, 0.02, 0.03, 0.02, 0.05, 0.02, 0.02, 0.04, 0.04, 0.03, 0.03, 0.02, 0.04, 0.03, 0.0 ...too long
./HTRU_2_16107_9 exists
argv:
	ds_name: HTRU_2
	base_folder: ./HTRU_2_16107_9
	f: <function f_opt at 0x000001B09E8EBA60>
	solver: <function solver_sklearn at 0x000001B09E8EB9D8>
	Q: {'path': './HTRU_2_16107_9/Q2.pt', 'init_size': 10, 'init_miu': 0, 'init_std': 1, 'sample_step': 0.1, 'epochs': 1000, 'bs': 1000, 'lr': 0.0005, 'mv': {'factor': 0.1, 'patience': 100000, 'min_lr': 0.0001}, 'infoQ_show_er': True, 'trainQ_s': 8000, 'valQ_s': 1600, 'testQ_s': 800}
	color_dict: {'SGD': 'b', 'MURAD': 'g', 'UNI': 'r'}
	Bal: {'folder': './HTRU_2_16107_9/Q2', 'reps': 5, 'epochs': 200, 'bs': 25, 'lr': 0.001, 'mv': {'factor': 0.1, 'patience': 500, 'min_lr': 0.0001}, 'lambda': 1, 'epochs_info': True, 'epochs_info_stds': False, 'batches_info': False, 'loss_stats': True}
	show_plots: False
	save_plots: True
	c_sizes: [1000]
	reps: 100
./HTRU_2_16107_9/Q2 created
get_Q_sets
build_Q:
	|initQ|=[10, 9, 1]:
		loss(A,q_opt)      =              885.38(avg=0.05)
		avg loss(A,initQ  )=           31,027.37(avg=1.93,std=1.07,min=0.42, max=3.53)
		avg |1- loss(A,q)/loss(A,q_opt)|=34.044(std=19.45,min=6.63, max=63.20))
1/10
build_Q:
	epochs 1000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(1000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=2000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 39,600.666. avg=2.459
Training...
	epoch [100/1000]: avg loss:0.599, diff=9.899029, lr=0.00050, |Q|=200
	epoch [200/1000]: avg loss:0.111, diff=1.027135, lr=0.00050, |Q|=400
	epoch [300/1000]: avg loss:0.062, diff=0.123058, lr=0.00050, |Q|=600
	epoch [400/1000]: avg loss:0.057, diff=0.034036, lr=0.00050, |Q|=800
	epoch [500/1000]: avg loss:0.056, diff=0.010920, lr=0.00050, |Q|=1000
	epoch [600/1000]: avg loss:0.055, diff=0.006371, lr=0.00050, |Q|=1200
	epoch [700/1000]: avg loss:0.055, diff=0.005502, lr=0.00050, |Q|=1400
	epoch [800/1000]: avg loss:0.055, diff=0.006479, lr=0.00050, |Q|=1600
	epoch [900/1000]: avg loss:0.055, diff=0.007994, lr=0.00050, |Q|=1800
	epoch [1000/1000]: avg loss:0.055, diff=0.009230, lr=0.00050, |Q|=2000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.055 (epoch 683)
	best_diff=0.005440
2/10
build_Q:
	epochs 1000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(1000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=2000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 56,840.271. avg=3.529
Training...
	epoch [100/1000]: avg loss:0.902, diff=15.401243, lr=0.00050, |Q|=200
	epoch [200/1000]: avg loss:0.151, diff=1.741307, lr=0.00050, |Q|=400
	epoch [300/1000]: avg loss:0.074, diff=0.355195, lr=0.00050, |Q|=600
	epoch [400/1000]: avg loss:0.064, diff=0.159294, lr=0.00050, |Q|=800
	epoch [500/1000]: avg loss:0.061, diff=0.113960, lr=0.00050, |Q|=1000
	epoch [600/1000]: avg loss:0.059, diff=0.081146, lr=0.00050, |Q|=1200
	epoch [700/1000]: avg loss:0.058, diff=0.053544, lr=0.00050, |Q|=1400
	epoch [800/1000]: avg loss:0.057, diff=0.036690, lr=0.00050, |Q|=1600
	epoch [900/1000]: avg loss:0.056, diff=0.027138, lr=0.00050, |Q|=1800
	epoch [1000/1000]: avg loss:0.056, diff=0.021416, lr=0.00050, |Q|=2000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1000)
	best_diff=0.021416
3/10
build_Q:
	epochs 1000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(1000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=2000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 21,864.505. avg=1.357
Training...
	epoch [100/1000]: avg loss:0.523, diff=8.520036, lr=0.00050, |Q|=200
	epoch [200/1000]: avg loss:0.100, diff=0.826277, lr=0.00050, |Q|=400
	epoch [300/1000]: avg loss:0.065, diff=0.174336, lr=0.00050, |Q|=600
	epoch [400/1000]: avg loss:0.061, diff=0.113897, lr=0.00050, |Q|=800
	epoch [500/1000]: avg loss:0.059, diff=0.079598, lr=0.00050, |Q|=1000
	epoch [600/1000]: avg loss:0.058, diff=0.054134, lr=0.00050, |Q|=1200
	epoch [700/1000]: avg loss:0.057, diff=0.038394, lr=0.00050, |Q|=1400
	epoch [800/1000]: avg loss:0.057, diff=0.028846, lr=0.00050, |Q|=1600
	epoch [900/1000]: avg loss:0.056, diff=0.022837, lr=0.00050, |Q|=1800
	epoch [1000/1000]: avg loss:0.056, diff=0.018703, lr=0.00050, |Q|=2000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1000)
	best_diff=0.018703
4/10
build_Q:
	epochs 1000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(1000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=2000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 47,303.478. avg=2.937
Training...
	epoch [100/1000]: avg loss:1.381, diff=24.115953, lr=0.00050, |Q|=200
	epoch [200/1000]: avg loss:0.499, diff=8.079916, lr=0.00050, |Q|=400
	epoch [300/1000]: avg loss:0.192, diff=2.498572, lr=0.00050, |Q|=600
	epoch [400/1000]: avg loss:0.082, diff=0.491548, lr=0.00050, |Q|=800
	epoch [500/1000]: avg loss:0.060, diff=0.095811, lr=0.00050, |Q|=1000
	epoch [600/1000]: avg loss:0.058, diff=0.056538, lr=0.00050, |Q|=1200
	epoch [700/1000]: avg loss:0.057, diff=0.040737, lr=0.00050, |Q|=1400
	epoch [800/1000]: avg loss:0.057, diff=0.030381, lr=0.00050, |Q|=1600
	epoch [900/1000]: avg loss:0.056, diff=0.024277, lr=0.00050, |Q|=1800
	epoch [1000/1000]: avg loss:0.056, diff=0.019953, lr=0.00050, |Q|=2000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1000)
	best_diff=0.019953
5/10
build_Q:
	epochs 1000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(1000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=2000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 10,259.631. avg=0.637
Training...
	epoch [100/1000]: avg loss:0.087, diff=0.585579, lr=0.00050, |Q|=200
	epoch [200/1000]: avg loss:0.064, diff=0.161114, lr=0.00050, |Q|=400
	epoch [300/1000]: avg loss:0.060, diff=0.100003, lr=0.00050, |Q|=600
	epoch [400/1000]: avg loss:0.059, diff=0.065286, lr=0.00050, |Q|=800
	epoch [500/1000]: avg loss:0.057, diff=0.035882, lr=0.00050, |Q|=1000
	epoch [600/1000]: avg loss:0.056, diff=0.021433, lr=0.00050, |Q|=1200
	epoch [700/1000]: avg loss:0.056, diff=0.016226, lr=0.00050, |Q|=1400
	epoch [800/1000]: avg loss:0.056, diff=0.014198, lr=0.00050, |Q|=1600
	epoch [900/1000]: avg loss:0.056, diff=0.013177, lr=0.00050, |Q|=1800
	epoch [1000/1000]: avg loss:0.056, diff=0.012624, lr=0.00050, |Q|=2000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 999)
	best_diff=0.012614
6/10
build_Q:
	epochs 1000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(1000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=2000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 54,372.279. avg=3.376
Training...
	epoch [100/1000]: avg loss:1.396, diff=24.402485, lr=0.00050, |Q|=200
	epoch [200/1000]: avg loss:0.474, diff=7.615108, lr=0.00050, |Q|=400
	epoch [300/1000]: avg loss:0.072, diff=0.309878, lr=0.00050, |Q|=600
	epoch [400/1000]: avg loss:0.060, diff=0.083229, lr=0.00050, |Q|=800
	epoch [500/1000]: avg loss:0.058, diff=0.052369, lr=0.00050, |Q|=1000
	epoch [600/1000]: avg loss:0.057, diff=0.039412, lr=0.00050, |Q|=1200
	epoch [700/1000]: avg loss:0.057, diff=0.030774, lr=0.00050, |Q|=1400
	epoch [800/1000]: avg loss:0.056, diff=0.024795, lr=0.00050, |Q|=1600
	epoch [900/1000]: avg loss:0.056, diff=0.020023, lr=0.00050, |Q|=1800
	epoch [1000/1000]: avg loss:0.056, diff=0.016885, lr=0.00050, |Q|=2000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1000)
	best_diff=0.016885
7/10
build_Q:
	epochs 1000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(1000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=2000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 13,517.834. avg=0.839
Training...
	epoch [100/1000]: avg loss:0.161, diff=1.933758, lr=0.00050, |Q|=200
	epoch [200/1000]: avg loss:0.086, diff=0.557277, lr=0.00050, |Q|=400
	epoch [300/1000]: avg loss:0.075, diff=0.368379, lr=0.00050, |Q|=600
	epoch [400/1000]: avg loss:0.069, diff=0.263255, lr=0.00050, |Q|=800
	epoch [500/1000]: avg loss:0.064, diff=0.171433, lr=0.00050, |Q|=1000
	epoch [600/1000]: avg loss:0.060, diff=0.098066, lr=0.00050, |Q|=1200
	epoch [700/1000]: avg loss:0.058, diff=0.053953, lr=0.00050, |Q|=1400
	epoch [800/1000]: avg loss:0.057, diff=0.033796, lr=0.00050, |Q|=1600
	epoch [900/1000]: avg loss:0.056, diff=0.025011, lr=0.00050, |Q|=1800
	epoch [1000/1000]: avg loss:0.056, diff=0.020123, lr=0.00050, |Q|=2000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1000)
	best_diff=0.020123
8/10
build_Q:
	epochs 1000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(1000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=2000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 30,520.921. avg=1.895
Training...
	epoch [100/1000]: avg loss:0.484, diff=7.806101, lr=0.00050, |Q|=200
	epoch [200/1000]: avg loss:0.145, diff=1.633434, lr=0.00050, |Q|=400
	epoch [300/1000]: avg loss:0.078, diff=0.425258, lr=0.00050, |Q|=600
	epoch [400/1000]: avg loss:0.067, diff=0.215712, lr=0.00050, |Q|=800
	epoch [500/1000]: avg loss:0.063, diff=0.140656, lr=0.00050, |Q|=1000
	epoch [600/1000]: avg loss:0.060, diff=0.095353, lr=0.00050, |Q|=1200
	epoch [700/1000]: avg loss:0.058, diff=0.064147, lr=0.00050, |Q|=1400
	epoch [800/1000]: avg loss:0.057, diff=0.044485, lr=0.00050, |Q|=1600
	epoch [900/1000]: avg loss:0.057, diff=0.032533, lr=0.00050, |Q|=1800
	epoch [1000/1000]: avg loss:0.056, diff=0.025484, lr=0.00050, |Q|=2000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1000)
	best_diff=0.025484
9/10
build_Q:
	epochs 1000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(1000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=2000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 6,754.933. avg=0.419
Training...
	epoch [100/1000]: avg loss:0.096, diff=0.751221, lr=0.00050, |Q|=200
	epoch [200/1000]: avg loss:0.075, diff=0.366522, lr=0.00050, |Q|=400
	epoch [300/1000]: avg loss:0.067, diff=0.215646, lr=0.00050, |Q|=600
	epoch [400/1000]: avg loss:0.062, diff=0.128380, lr=0.00050, |Q|=800
	epoch [500/1000]: avg loss:0.059, diff=0.074237, lr=0.00050, |Q|=1000
	epoch [600/1000]: avg loss:0.058, diff=0.046385, lr=0.00050, |Q|=1200
	epoch [700/1000]: avg loss:0.057, diff=0.032256, lr=0.00050, |Q|=1400
	epoch [800/1000]: avg loss:0.056, diff=0.024782, lr=0.00050, |Q|=1600
	epoch [900/1000]: avg loss:0.056, diff=0.020155, lr=0.00050, |Q|=1800
	epoch [1000/1000]: avg loss:0.056, diff=0.017197, lr=0.00050, |Q|=2000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1000)
	best_diff=0.017197
10/10
build_Q:
	epochs 1000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(1000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=2000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 29,239.163. avg=1.815
Training...
	epoch [100/1000]: avg loss:0.306, diff=4.561414, lr=0.00050, |Q|=200
	epoch [200/1000]: avg loss:0.092, diff=0.668167, lr=0.00050, |Q|=400
	epoch [300/1000]: avg loss:0.067, diff=0.212671, lr=0.00050, |Q|=600
	epoch [400/1000]: avg loss:0.063, diff=0.137957, lr=0.00050, |Q|=800
	epoch [500/1000]: avg loss:0.060, diff=0.099980, lr=0.00050, |Q|=1000
	epoch [600/1000]: avg loss:0.059, diff=0.070145, lr=0.00050, |Q|=1200
	epoch [700/1000]: avg loss:0.058, diff=0.048411, lr=0.00050, |Q|=1400
	epoch [800/1000]: avg loss:0.057, diff=0.035070, lr=0.00050, |Q|=1600
	epoch [900/1000]: avg loss:0.056, diff=0.026913, lr=0.00050, |Q|=1800
	epoch [1000/1000]: avg loss:0.056, diff=0.021542, lr=0.00050, |Q|=2000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1000)
	best_diff=0.021542
Saved to: ./HTRU_2_16107_9/Q2.pt
	Q(torch.Tensor,s=torch.Size([20000, 9, 1]),dtype=torch.float64,trainable=False,is_cuda=False): [[[1.92], [1.48], [0.91], [-2.1], [0.68], [-1.23], [-0.05], [-1.6], [-0.76]], [[1.92], [1.48], [0.91 ...too long
	|allQ|=[20000, 9, 1]:
		loss(A,q_opt)      =              885.38(avg=0.05)
		avg loss(A,allQ   )=            3,278.60(avg=0.20,std=0.44,min=0.06, max=3.52)
		avg |1- loss(A,q)/loss(A,q_opt)|=2.703(std=8.03,min=0.01, max=62.97))
	|trainQ|=[8000, 9, 1]:
		loss(A,q_opt)      =              885.38(avg=0.05)
		avg loss(A,trainQ )=            3,204.78(avg=0.20,std=0.43,min=0.06, max=3.49)
		avg |1- loss(A,q)/loss(A,q_opt)|=2.620(std=7.85,min=0.01, max=62.44))
	|valQ|=[1600, 9, 1]:
		loss(A,q_opt)      =              885.38(avg=0.05)
		avg loss(A,valQ   )=            3,164.27(avg=0.20,std=0.43,min=0.06, max=3.44)
		avg |1- loss(A,q)/loss(A,q_opt)|=2.574(std=7.75,min=0.01, max=61.65))
	|testQ|=[800, 9, 1]:
		loss(A,q_opt)      =              885.38(avg=0.05)
		avg loss(A,testQ  )=            3,232.27(avg=0.20,std=0.42,min=0.06, max=2.92)
		avg |1- loss(A,q)/loss(A,q_opt)|=2.651(std=7.58,min=0.01, max=52.04))
working on CPU
get_Q_sets time 00:02:35
--------------------------------------------------------------------------------
Total run time 0:02:35

Process finished with exit code 0
