C:\Users\GiladEiniKbyLake\.conda\envs\AutoCL2\python.exe D:/workspace/2019SGD/DataReduction/SVM/mainSVM.py
--------------------------------------------------------------------------------
main_wrapper:
* Run started at 16-06-2022 20:36:53
* Python Version 3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]
* Operating System uname_result(system='Windows', node='Wizzi-Dorms', release='10', version='10.0.19041', machine='AMD64', processor='Intel64 Family 6 Model 158 Stepping 9, GenuineIntel')
* Interpreter: C:\Users\GiladEiniKbyLake\.conda\envs\AutoCL2\python.exe
* wizzi_utils Version 7.0.15
* Working Dir: D:\workspace\2019SGD\DataReduction\SVM
* Computer Mac: 70:4D:7B:8A:65:EE
* CPU Info: AMD64, Intel64 Family 6 Model 158 Stepping 9, GenuineIntel, Physical cores 4, Total cores 8, Frequency 3601.00Mhz, CPU Usage 22.8%
* Physical Memory: C: Total 232.33 GB, Used 208.19 GB(89.60%), Free 24.14 GB, D: Total 931.39 GB, Used 241.0 GB(25.90%), Free 690.39 GB, E: PermissionError: [WinError 21] The device is not ready: 'E', G: Total 17.0 GB, Used 3.2 GB(18.80%), Free 13.8 GB
* RAM: Total 15.94 GB, Used 5.38 GB(33.7%), Available 10.56 GB
* CUDA Version: v10.2 (cuDNN Version 7.6.5) (Turned off)
* PyTorch Version 1.8.1+cu101 - GPU detected ? False
Function <function main at 0x000001CDA1600C80> started:
--------------------------------------------------------------------------------
working on CPU
A_train(numpy.ndarray,s=(16107, 9),dtype=float64): [[0.03, 0.23, -0.24, -0.3, -0.38, -0.74, 1.14, 1.2, -1.0], [-1.26, -1.4, 0.25, 0.23, -0.17, 0.42, -0 ...too long
A_test(numpy.ndarray,s=(1790, 9),dtype=float64): [[0.29, 0.24, -0.37, -0.29, -0.35, -0.66, 0.3, 0.23, -1.0], [1.24, -0.29, -0.66, -0.24, -0.25, 0.07, ...too long
SP_train(numpy.ndarray,s=(16107,),dtype=float64): [0.04, 0.06, 0.04, 0.02, 0.03, 0.02, 0.05, 0.02, 0.02, 0.04, 0.04, 0.03, 0.03, 0.02, 0.04, 0.03, 0.0 ...too long
./HTRU_2_16107_9 exists
argv:
	ds_name: HTRU_2
	base_folder: ./HTRU_2_16107_9
	f: <function f_opt at 0x000001CDA15EBA60>
	solver: <function solver_sklearn at 0x000001CDA15EB9D8>
	Q: {'path': './HTRU_2_16107_9/Q32.pt', 'init_size': 10, 'init_miu': 0, 'init_std': 1, 'sample_step': 0.1, 'epochs': 2000, 'bs': 1000, 'lr': 0.0005, 'mv': {'factor': 0.1, 'patience': 100000, 'min_lr': 0.0001}, 'infoQ_show_er': True, 'trainQ_s': 8000, 'valQ_s': 1600, 'testQ_s': 800}
	color_dict: {'SGD': 'b', 'MURAD': 'g', 'UNI': 'r'}
	Bal: {'folder': './HTRU_2_16107_9/Q3', 'reps': 5, 'epochs': 300, 'bs': 100, 'lr': 0.001, 'mv': {'factor': 0.1, 'patience': 500, 'min_lr': 0.0001}, 'lambda': 1, 'epochs_info': True, 'epochs_info_stds': False, 'batches_info': False, 'loss_stats': True}
	show_plots: False
	save_plots: True
	c_sizes: [800]
	reps: 100
./HTRU_2_16107_9/Q3 created
get_Q_sets
build_Q:
	|initQ|=[10, 9, 1]:
		loss(A,q_opt)      =              885.38(avg=0.05)
		avg loss(A,initQ  )=           31,027.37(avg=1.93,std=1.07,min=0.42, max=3.53)
		avg |1- loss(A,q)/loss(A,q_opt)|=34.044(std=19.45,min=6.63, max=63.20))
1/10
build_Q:
	epochs 2000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(2000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=4000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 39,600.666. avg=2.459
Training...
	epoch [200/2000]: avg loss:0.111, diff=1.027135, lr=0.00050, |Q|=400
	epoch [400/2000]: avg loss:0.057, diff=0.034036, lr=0.00050, |Q|=800
	epoch [600/2000]: avg loss:0.055, diff=0.006371, lr=0.00050, |Q|=1200
	epoch [800/2000]: avg loss:0.055, diff=0.006479, lr=0.00050, |Q|=1600
	epoch [1000/2000]: avg loss:0.055, diff=0.009230, lr=0.00050, |Q|=2000
	epoch [1200/2000]: avg loss:0.056, diff=0.010612, lr=0.00050, |Q|=2400
	epoch [1400/2000]: avg loss:0.056, diff=0.011373, lr=0.00050, |Q|=2800
	epoch [1600/2000]: avg loss:0.056, diff=0.011777, lr=0.00050, |Q|=3200
	epoch [1800/2000]: avg loss:0.056, diff=0.011930, lr=0.00050, |Q|=3600
	epoch [2000/2000]: avg loss:0.056, diff=0.012001, lr=0.00050, |Q|=4000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.055 (epoch 683)
	best_diff=0.005440
2/10
build_Q:
	epochs 2000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(2000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=4000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 56,840.271. avg=3.529
Training...
	epoch [200/2000]: avg loss:0.151, diff=1.741431, lr=0.00050, |Q|=400
	epoch [400/2000]: avg loss:0.064, diff=0.159380, lr=0.00050, |Q|=800
	epoch [600/2000]: avg loss:0.059, diff=0.081180, lr=0.00050, |Q|=1200
	epoch [800/2000]: avg loss:0.057, diff=0.036709, lr=0.00050, |Q|=1600
	epoch [1000/2000]: avg loss:0.056, diff=0.021420, lr=0.00050, |Q|=2000
	epoch [1200/2000]: avg loss:0.056, diff=0.015544, lr=0.00050, |Q|=2400
	epoch [1400/2000]: avg loss:0.056, diff=0.012925, lr=0.00050, |Q|=2800
	epoch [1600/2000]: avg loss:0.056, diff=0.012214, lr=0.00050, |Q|=3200
	epoch [1800/2000]: avg loss:0.056, diff=0.012028, lr=0.00050, |Q|=3600
	epoch [2000/2000]: avg loss:0.056, diff=0.012015, lr=0.00050, |Q|=4000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1843)
	best_diff=0.011981
3/10
build_Q:
	epochs 2000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(2000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=4000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 21,864.505. avg=1.357
Training...
	epoch [200/2000]: avg loss:0.100, diff=0.827211, lr=0.00050, |Q|=400
	epoch [400/2000]: avg loss:0.061, diff=0.113933, lr=0.00050, |Q|=800
	epoch [600/2000]: avg loss:0.058, diff=0.054098, lr=0.00050, |Q|=1200
	epoch [800/2000]: avg loss:0.057, diff=0.028917, lr=0.00050, |Q|=1600
	epoch [1000/2000]: avg loss:0.056, diff=0.018762, lr=0.00050, |Q|=2000
	epoch [1200/2000]: avg loss:0.056, diff=0.014186, lr=0.00050, |Q|=2400
	epoch [1400/2000]: avg loss:0.056, diff=0.012932, lr=0.00050, |Q|=2800
	epoch [1600/2000]: avg loss:0.056, diff=0.012389, lr=0.00050, |Q|=3200
	epoch [1800/2000]: avg loss:0.056, diff=0.012141, lr=0.00050, |Q|=3600
	epoch [2000/2000]: avg loss:0.056, diff=0.012084, lr=0.00050, |Q|=4000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1980)
	best_diff=0.012059
4/10
build_Q:
	epochs 2000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(2000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=4000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 47,303.478. avg=2.937
Training...
	epoch [200/2000]: avg loss:0.499, diff=8.081880, lr=0.00050, |Q|=400
	epoch [400/2000]: avg loss:0.082, diff=0.495031, lr=0.00050, |Q|=800
	epoch [600/2000]: avg loss:0.058, diff=0.056505, lr=0.00050, |Q|=1200
	epoch [800/2000]: avg loss:0.057, diff=0.030403, lr=0.00050, |Q|=1600
	epoch [1000/2000]: avg loss:0.056, diff=0.019924, lr=0.00050, |Q|=2000
	epoch [1200/2000]: avg loss:0.056, diff=0.014926, lr=0.00050, |Q|=2400
	epoch [1400/2000]: avg loss:0.056, diff=0.012755, lr=0.00050, |Q|=2800
	epoch [1600/2000]: avg loss:0.056, diff=0.012201, lr=0.00050, |Q|=3200
	epoch [1800/2000]: avg loss:0.056, diff=0.012063, lr=0.00050, |Q|=3600
	epoch [2000/2000]: avg loss:0.056, diff=0.012045, lr=0.00050, |Q|=4000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1958)
	best_diff=0.012007
5/10
build_Q:
	epochs 2000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(2000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=4000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 10,259.631. avg=0.637
Training...
	epoch [200/2000]: avg loss:0.064, diff=0.161222, lr=0.00050, |Q|=400
	epoch [400/2000]: avg loss:0.059, diff=0.065168, lr=0.00050, |Q|=800
	epoch [600/2000]: avg loss:0.056, diff=0.021591, lr=0.00050, |Q|=1200
	epoch [800/2000]: avg loss:0.056, diff=0.014146, lr=0.00050, |Q|=1600
	epoch [1000/2000]: avg loss:0.056, diff=0.012600, lr=0.00050, |Q|=2000
	epoch [1200/2000]: avg loss:0.056, diff=0.012146, lr=0.00050, |Q|=2400
	epoch [1400/2000]: avg loss:0.056, diff=0.012065, lr=0.00050, |Q|=2800
	epoch [1600/2000]: avg loss:0.056, diff=0.012020, lr=0.00050, |Q|=3200
	epoch [1800/2000]: avg loss:0.056, diff=0.012031, lr=0.00050, |Q|=3600
	epoch [2000/2000]: avg loss:0.056, diff=0.012025, lr=0.00050, |Q|=4000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1987)
	best_diff=0.011994
6/10
build_Q:
	epochs 2000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(2000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=4000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 54,372.279. avg=3.376
Training...
	epoch [200/2000]: avg loss:0.474, diff=7.616844, lr=0.00050, |Q|=400
	epoch [400/2000]: avg loss:0.060, diff=0.083237, lr=0.00050, |Q|=800
	epoch [600/2000]: avg loss:0.057, diff=0.039436, lr=0.00050, |Q|=1200
	epoch [800/2000]: avg loss:0.056, diff=0.024676, lr=0.00050, |Q|=1600
	epoch [1000/2000]: avg loss:0.056, diff=0.016751, lr=0.00050, |Q|=2000
	epoch [1200/2000]: avg loss:0.056, diff=0.013577, lr=0.00050, |Q|=2400
	epoch [1400/2000]: avg loss:0.056, diff=0.012724, lr=0.00050, |Q|=2800
	epoch [1600/2000]: avg loss:0.056, diff=0.012297, lr=0.00050, |Q|=3200
	epoch [1800/2000]: avg loss:0.056, diff=0.012137, lr=0.00050, |Q|=3600
	epoch [2000/2000]: avg loss:0.056, diff=0.012074, lr=0.00050, |Q|=4000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1960)
	best_diff=0.012051
7/10
build_Q:
	epochs 2000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(2000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=4000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 13,517.834. avg=0.839
Training...
	epoch [200/2000]: avg loss:0.086, diff=0.556619, lr=0.00050, |Q|=400
	epoch [400/2000]: avg loss:0.069, diff=0.263074, lr=0.00050, |Q|=800
	epoch [600/2000]: avg loss:0.060, diff=0.097495, lr=0.00050, |Q|=1200
	epoch [800/2000]: avg loss:0.057, diff=0.033974, lr=0.00050, |Q|=1600
	epoch [1000/2000]: avg loss:0.056, diff=0.020233, lr=0.00050, |Q|=2000
	epoch [1200/2000]: avg loss:0.056, diff=0.015388, lr=0.00050, |Q|=2400
	epoch [1400/2000]: avg loss:0.056, diff=0.012931, lr=0.00050, |Q|=2800
	epoch [1600/2000]: avg loss:0.056, diff=0.012118, lr=0.00050, |Q|=3200
	epoch [1800/2000]: avg loss:0.056, diff=0.011899, lr=0.00050, |Q|=3600
	epoch [2000/2000]: avg loss:0.056, diff=0.011913, lr=0.00050, |Q|=4000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1840)
	best_diff=0.011840
8/10
build_Q:
	epochs 2000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(2000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=4000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 30,520.921. avg=1.895
Training...
	epoch [200/2000]: avg loss:0.145, diff=1.628781, lr=0.00050, |Q|=400
	epoch [400/2000]: avg loss:0.067, diff=0.215659, lr=0.00050, |Q|=800
	epoch [600/2000]: avg loss:0.060, diff=0.095367, lr=0.00050, |Q|=1200
	epoch [800/2000]: avg loss:0.057, diff=0.044702, lr=0.00050, |Q|=1600
	epoch [1000/2000]: avg loss:0.056, diff=0.025781, lr=0.00050, |Q|=2000
	epoch [1200/2000]: avg loss:0.056, diff=0.017465, lr=0.00050, |Q|=2400
	epoch [1400/2000]: avg loss:0.056, diff=0.013749, lr=0.00050, |Q|=2800
	epoch [1600/2000]: avg loss:0.056, diff=0.012729, lr=0.00050, |Q|=3200
	epoch [1800/2000]: avg loss:0.056, diff=0.012301, lr=0.00050, |Q|=3600
	epoch [2000/2000]: avg loss:0.056, diff=0.012116, lr=0.00050, |Q|=4000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1992)
	best_diff=0.012100
9/10
build_Q:
	epochs 2000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(2000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=4000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 6,754.933. avg=0.419
Training...
	epoch [200/2000]: avg loss:0.075, diff=0.365881, lr=0.00050, |Q|=400
	epoch [400/2000]: avg loss:0.062, diff=0.128619, lr=0.00050, |Q|=800
	epoch [600/2000]: avg loss:0.058, diff=0.046310, lr=0.00050, |Q|=1200
	epoch [800/2000]: avg loss:0.056, diff=0.024715, lr=0.00050, |Q|=1600
	epoch [1000/2000]: avg loss:0.056, diff=0.017260, lr=0.00050, |Q|=2000
	epoch [1200/2000]: avg loss:0.056, diff=0.013643, lr=0.00050, |Q|=2400
	epoch [1400/2000]: avg loss:0.056, diff=0.012375, lr=0.00050, |Q|=2800
	epoch [1600/2000]: avg loss:0.056, diff=0.011993, lr=0.00050, |Q|=3200
	epoch [1800/2000]: avg loss:0.056, diff=0.011955, lr=0.00050, |Q|=3600
	epoch [2000/2000]: avg loss:0.056, diff=0.011994, lr=0.00050, |Q|=4000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1755)
	best_diff=0.011913
10/10
build_Q:
	epochs 2000, bs 1000, #batches 17, base lr 0.0005
	In each epoch(2000 total) there are 17 batches(different qs). sample 10.0%(2) from them. expected |Q|=4000
	early stop if |1-loss_q/loss_q_opt|< 0.001
	Opt loss 885.381. avg=0.055
	Our loss 29,239.163. avg=1.815
Training...
	epoch [200/2000]: avg loss:0.092, diff=0.668354, lr=0.00050, |Q|=400
	epoch [400/2000]: avg loss:0.063, diff=0.137984, lr=0.00050, |Q|=800
	epoch [600/2000]: avg loss:0.059, diff=0.070385, lr=0.00050, |Q|=1200
	epoch [800/2000]: avg loss:0.057, diff=0.035473, lr=0.00050, |Q|=1600
	epoch [1000/2000]: avg loss:0.056, diff=0.021733, lr=0.00050, |Q|=2000
	epoch [1200/2000]: avg loss:0.056, diff=0.015427, lr=0.00050, |Q|=2400
	epoch [1400/2000]: avg loss:0.056, diff=0.013204, lr=0.00050, |Q|=2800
	epoch [1600/2000]: avg loss:0.056, diff=0.012490, lr=0.00050, |Q|=3200
	epoch [1800/2000]: avg loss:0.056, diff=0.012174, lr=0.00050, |Q|=3600
	epoch [2000/2000]: avg loss:0.056, diff=0.012086, lr=0.00050, |Q|=4000
Done training. Results:
	Opt avg loss 0.055
	Our avg loss 0.056 (epoch 1999)
	best_diff=0.012057
Saved to: ./HTRU_2_16107_9/Q32.pt
	Q(torch.Tensor,s=torch.Size([40000, 9, 1]),dtype=torch.float64,trainable=False,is_cuda=False): [[[1.92], [1.48], [0.91], [-2.1], [0.68], [-1.23], [-0.05], [-1.6], [-0.76]], [[1.92], [1.48], [0.91 ...too long
	|allQ|=[40000, 9, 1]:
		loss(A,q_opt)      =              885.38(avg=0.05)
		avg loss(A,allQ   )=            2,087.89(avg=0.13,std=0.32,min=0.06, max=3.53)
		avg |1- loss(A,q)/loss(A,q_opt)|=1.358(std=5.84,min=0.01, max=63.17))
	|trainQ|=[8000, 9, 1]:
		loss(A,q_opt)      =              885.38(avg=0.05)
		avg loss(A,trainQ )=            2,127.23(avg=0.13,std=0.32,min=0.06, max=3.48)
		avg |1- loss(A,q)/loss(A,q_opt)|=1.403(std=5.86,min=0.01, max=62.35))
	|valQ|=[1600, 9, 1]:
		loss(A,q_opt)      =              885.38(avg=0.05)
		avg loss(A,valQ   )=            2,236.88(avg=0.14,std=0.34,min=0.06, max=3.24)
		avg |1- loss(A,q)/loss(A,q_opt)|=1.526(std=6.28,min=0.01, max=57.94))
	|testQ|=[800, 9, 1]:
		loss(A,q_opt)      =              885.38(avg=0.05)
		avg loss(A,testQ  )=            2,158.11(avg=0.13,std=0.34,min=0.06, max=2.83)
		avg |1- loss(A,q)/loss(A,q_opt)|=1.437(std=6.15,min=0.01, max=50.49))
working on CPU
get_Q_sets time 00:03:16
--------------------------------------------------------------------------------
Total run time 0:03:16

Process finished with exit code 0
